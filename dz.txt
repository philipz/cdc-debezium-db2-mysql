docker run -d --name zookeeper -p 2181:2181 -p 2888:2888 -p 3888:3888 debezium/zookeeper
docker run -d --name kafka -p 9092:9092 --link zookeeper:zookeeper debezium/kafka

docker run -d --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=debezium -e MYSQL_USER=mysqluser -e MYSQL_PASSWORD=mysqlpw debezium/example-mysql:1.0

docker run -d --name mydb2 --privileged=true -p 50000:50000 -e LICENSE=accept -e DB2INST1_PASSWORD=password -e DBNAME=testdb  ibmcom/db2

docker run -d --name connect -p 8083:8083 -e GROUP_ID=1 -e CONFIG_STORAGE_TOPIC=my_connect_configs -e OFFSET_STORAGE_TOPIC=my_connect_offsets -e STATUS_STORAGE_TOPIC=my_connect_statuses --link zookeeper:zookeeper --link kafka:kafka --link mysql:mysql philipz/debezium-connect:1.4

DB2 Docker:

Copy the contents of the github repo into the container:
  docker cp ./debezium-connector-db2 mydb2:/database

Login to the container
  docker exec -it mydb2 sh

Change to db2inst1 user
  su - db2inst1
  mkdir -p asncdctools/src
  cd ~
  cp -r /database/debezium-connector-db2/src/test/docker/db2-cdc-docker/** $HOME/asncdctools/src/
  cd $HOME/sqllib/samples/c/
  cp ./bldrtn $HOME/asncdctools/src
  cd $HOME/asncdctools/src
  ./bldrtn asncdc
  cd $HOME/sqllib/bnd
  db2 connect to testdb
  db2 bind db2schema.bnd blocking all grant public sqlerror continue
  cp $HOME/asncdctools/src/asncdc $HOME/sqllib/function
  chmod 777 $HOME/sqllib/function
  db2 -tvmf $HOME/asncdctools/src/asncdc_UDF.sql
  db2 -tvmf $HOME/asncdctools/src/asncdctables.sql
  db2 -tvmf $HOME/asncdctools/src/asncdcaddremove.sql

Use DB client like DBeaver
Start the ASN agent:
VALUES ASNCDC.ASNCDCSERVICES('start','asncdc');
Check the ASN status
VALUES ASNCDC.ASNCDCSERVICES('status','asncdc');

CALL ASNCDC.ADDTABLE('TESTSCHEMA', 'CUSTOMERS');

CREATE TABLE TESTSCHEMA.customers (
 ID INTEGER generated always as identity (start with 1000 increment by 1) NOT NULL PRIMARY KEY,
 FIRST_NAME VARCHAR(255) NOT NULL,
 LAST_NAME VARCHAR(255) NOT NULL,
 EMAIL VARCHAR(255) NOT NULL UNIQUE
);

-- source connector with debezium connector
curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{
  "name": "db2-connector",
  "config": {
    "connector.class": "io.debezium.connector.db2.Db2Connector",
    "database.hostname": "db2",
    "database.port": "50000",
    "database.user": "db2inst1",
    "database.password": "password",
    "database.dbname": "testdb",
    "database.server.name": "testdb",
    "table.whitelist": "TESTSCHEMA.customers",
    "database.history.kafka.bootstrap.servers": "kafka:9092",
    "database.history.kafka.topic": "dbhistory.testdb",
    "transforms": "route",
    "transforms.route.type": "org.apache.kafka.connect.transforms.RegexRouter",
    "transforms.route.regex": "testdb.TESTSCHEMA.(.*)",
    "transforms.route.replacement": "$1"
  }
}'

  Response:
  HTTP/1.1 201 Created
  Date: Tue, 25 Feb 2020 07:21:34 GMT
  Location: http://localhost:8083/connectors/db2-connector
  Content-Type: application/json
  Content-Length: 458
  Server: Jetty(9.4.20.v20190813)

  {"name":"db2-connector","config":{"connector.class":"io.debezium.connector.db2.Db2Connector","database.hostname":"db2","database.port":"50000","database.user":"db2inst1","database.password":"password","database.dbname":"testdb","database.server.name":"testdb","table.whitelist":"TESTSCHEMA.customers","database.history.kafka.bootstrap.servers":"kafka:9092","database.history.kafka.topic":"dbhistory.testdb","name":"db2-connector"},"tasks":[],"type":"source"}‚èé


-- sink connector with confluent jdbc sink connector
curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{
    "name": "sink-mysql-connector",
    "config": {
        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
        "tasks.max": "1",
        "topics": "CUSTOMERS",
        "connection.url": "jdbc:mysql://mysql:3306/testschema?user=mysqluser&password=mysqlpw&nullCatalogMeansCurrent=true",
        "transforms": "unwrap",
        "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
        "transforms.unwrap.drop.tombstones": "false",
        "auto.create": "true",
        "insert.mode": "upsert",
        "delete.enabled": "true",
        "pk.fields": "ID",
        "pk.mode": "record_key"
    }
}'



--


add the unwrap header parameter on source side
setup sink connector to mysql
  link mysql connector to connect container
